{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["TglHVX_vRc0G","TeBxPbr2THb1","qkaGw83IV4FP","oJbZaA1vtQrr","0ltKde4Q1Mon","T3pHxGYQlt6h","a6B0XAZYuz_U"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from sklearn.datasets import make_circles\n","from sklearn.svm import SVC\n","from scipy.optimize import minimize\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","from tqdm.notebook import tqdm\n","\n","plt.style.use('ggplot')\n","%matplotlib inline\n","np.random.seed(0)"],"metadata":{"id":"_X1QKVLUbmZf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Напоминание из теории"],"metadata":{"id":"TglHVX_vRc0G"}},{"cell_type":"markdown","source":["В случае оптимального байесовского классификатора разделяющая поверхность будет задаваться уравнением\n","\n","$$\n","\\mathbb{P}(C_1|x) = \\mathbb{P}(C_2|x) \\Longleftrightarrow \\mathbb{P}(x|C_1)\\mathbb{P}(C_1) = \\mathbb{P}(x|C_2)\\mathbb{P}(C_2).\n","$$\n","\n","Теперь обсудим пример построения порождающей модели. Естественно, на основе нормального распределения или гауссианов. Пусть\n","\n","$$\n","\\mathbb{P}(x|C_i) = \\mathbb{N}(x|\\mu_i, \\Sigma_i).\n","$$\n","\n","Разделяющая поверхность будет иметь вид\n","\n","$$\n","\\ln \\mathbb{P}(C_1) - \\frac{1}{2}\\ln |\\Sigma_1| - \\frac{1}{2}(x-\\mu_1)^{T}\\Sigma_1^{-1}(x-\\mu_1) = \\ln \\mathbb{P}(C_2) - \\frac{1}{2}\\ln |\\Sigma_2| - \\frac{1}{2}(x-\\mu_2)^{T}\\Sigma_2^{-1}(x-\\mu_2).\n","$$\n","\n","Понятно, что разделяющая поверхность квадратичная. Для оценки параметров $\\mu_i$ и $\\Sigma_i$ имеет смысл использовать соответствующие выборочные характеристики (выборочное среднее и выборочная ковариационная матрица). Оценить $\\mathbb{P}(C_i)$ можно долей числа элементов соответствующего класса."],"metadata":{"id":"r3TcK_9PluJF"}},{"cell_type":"markdown","source":["# LDA"],"metadata":{"id":"TeBxPbr2THb1"}},{"cell_type":"markdown","source":["В рамках предположения, что $\\Sigma_1 = \\Sigma_2$ и\n","\n","$$\n","\\Sigma =  \\frac{|C_1|}{|C_1| + |C_2|}\\Sigma_1 + \\frac{|C_2|}{|C_1| + |C_2|}\\Sigma_2,\n","$$\n","\n","где\n","\n","$$\n","\\Sigma_i = \\frac{1}{|C_i|}\\sum_{x\\in C_i}\\left(x-\\mu_i\\right)\\left(x-\\mu_i\\right)^T\n","$$\n","\n","разделяющая поверхность будет иметь вид гиперплоскости\n","\n","$$\n","\\left(\\mu_2 - \\mu_1\\right)\\Sigma^{-1}x + \\frac{1}{2} \\left(\\mu_1^{T}\\Sigma^{-1}\\mu_1 - \\mu_2^{T}\\Sigma^{-1}\\mu_2\\right) + \\ln \\frac{\\mathbb{P}(C_2)}{\\mathbb{P}(C_1)} = 0.\n","$$"],"metadata":{"id":"wKtydmOBTJVx"}},{"cell_type":"markdown","source":["### Генерация данных"],"metadata":{"id":"qkaGw83IV4FP"}},{"cell_type":"code","source":["# 1. Генерация данных\n","np.random.seed(42)\n","\n","class_1_size = 100\n","class_2_size = 100\n","\n","class_1 = np.random.multivariate_normal(mean=[2, 2], cov=[[1, 0.5], [0.5, 1]], size=class_1_size)\n","class_2 = np.random.multivariate_normal(mean=[5, 5], cov=[[1, -0.5], [-0.5, 1]], size=class_2_size)\n","\n","# Объединение данных\n","X = np.vstack((class_1, class_2))\n","y = np.hstack((np.zeros(100), np.ones(100)))\n","\n","# Визуализация данных\n","plt.figure(figsize=(8,8))\n","plt.scatter(class_1[:, 0], class_1[:, 1], label='Class 1', c='blue', alpha=0.7)\n","plt.scatter(class_2[:, 0], class_2[:, 1], label='Class 2', c='red', alpha=0.7)\n","plt.legend()\n","plt.title('Исходные данные двух классов')\n","plt.xlabel('Признак 1')\n","plt.ylabel('Признак 2')\n","plt.axis('scaled')\n","plt.show()"],"metadata":{"id":"dgouQHg5uJl6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Вычисление параметров модели"],"metadata":{"id":"oJbZaA1vtQrr"}},{"cell_type":"code","source":["# Оценка среднего\n","def get_mu(class_objects):\n","    \"\"\"\n","    Параметры\n","    ----------\n","    class_objects : {array-like} формы (n_samples, n_features)\n","        Объекты одного класса, где `n_samples` — число объектов\n","        и `n_features` — число признаков.\n","\n","    Что возвращается\n","    -------\n","    mu : вектор из координат центроида класса\n","    \"\"\"\n","    return np.mean(class_objects, axis=0)\n","\n","mu_1 = get_mu(class_1)\n","mu_2 = get_mu(class_2)\n","assert np.isclose(mu_1, np.array([2.08307042, 2.11709274])).all() and np.isclose(mu_2, np.array([4.91067717, 5.13281048])).all()"],"metadata":{"id":"xvPsdtF8PsWG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Обращенная матрица ковариаций\n","def get_Sigma_inv(class_1, class_2, mu_1, mu_2):\n","    \"\"\"\n","    Параметры\n","    ----------\n","    class_1 : {array-like} формы (n_samples, n_features)\n","        Объекты класса 1, где `n_samples` — число объектов\n","        и `n_features` — число признаков.\n","    class_2 : {array-like} формы (n_samples, n_features)\n","        Объекты класса 2, где `n_samples` — число объектов\n","        и `n_features` — число признаков.\n","    mu_1 : {numpy.ndarray} — вектор из координат центроида класса 1\n","    mu_2 : {numpy.ndarray} — вектор из координат центроида класса 2\n","\n","    Что возвращается\n","    -------\n","    Sigma_inv : обращенная общая матрица ковариаций\n","    \"\"\"\n","    n1 = class_1.shape[0]\n","    n2 = class_2.shape[0]\n","    total = n1 + n2\n","\n","    # Вычисляем ковариационные матрицы для каждого класса\n","    centered_1 = class_1 - mu_1\n","    Sigma_1 = (centered_1.T @ centered_1) / n1\n","\n","    centered_2 = class_2 - mu_2\n","    Sigma_2 = (centered_2.T @ centered_2) / n2\n","\n","    # Взвешенное усреднение\n","    Sigma = (n1 / total) * Sigma_1 + (n2 / total) * Sigma_2\n","\n","    # Обращение матрицы\n","    Sigma_inv = np.linalg.inv(Sigma)\n","\n","    return Sigma_inv\n","\n","Sigma_inv = get_Sigma_inv(class_1, class_2, mu_1, mu_2)\n","assert np.isclose(Sigma_inv, np.array([[1.0782101, 0.18128796], [0.18128796, 1.19546925 ]])).all()"],"metadata":{"id":"Mep1PEOoRwm-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Нормальный вектор гиперплоскости\n","def get_w(mu_1, mu_2, Sigma_inv):\n","    \"\"\"\n","    Параметры\n","    ----------\n","    mu_1 : {numpy.ndarray} — вектор из координат центроида класса 1\n","    mu_2 : {numpy.ndarray} — вектор из координат центроида класса 2\n","    Sigma_inv : {numpy.ndarray} — обращенная общая матрица ковариаций\n","\n","    Что возвращается\n","    -------\n","    w : нормальный вектор гиперплоскости\n","    \"\"\"\n","    return Sigma_inv @ (mu_2 - mu_1)\n","\n","w = get_w(mu_1, mu_2, Sigma_inv)\n","assert np.isclose(w, np.array([3.59546745, 4.11780887])).all()"],"metadata":{"id":"ZI-lLK3_UieD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Коэффициент смещения гиперплоскости\n","def get_b(mu_1, mu_2, Sigma_inv, class_1_size, class_2_size):\n","    \"\"\"\n","    Параметры\n","    ----------\n","    mu_1 : {numpy.ndarray} — вектор из координат центроида класса 1\n","    mu_2 : {numpy.ndarray} — вектор из координат центроида класса 2\n","    Sigma_inv : {numpy.ndarray} — обращенная общая матрица ковариаций\n","    class_1_size : {int} — количество элементов класса 1\n","    class_2_size : {int} — количество элементов класса 2\n","\n","    Что возвращается\n","    -------\n","    b : коэффициент смещения гиперплоскости\n","    \"\"\"\n","    # Априорные лог-вероятности\n","    P_C2 = class_2_size / (class_1_size + class_2_size)\n","    P_C1 = class_1_size / (class_1_size + class_2_size)\n","    log_prior_ratio = np.log(P_C2 / P_C1)\n","\n","    # Квадратичные члены\n","    mu1_S_inv_mu1 = mu_1 @ Sigma_inv @ mu_1\n","    mu2_S_inv_mu2 = mu_2 @ Sigma_inv @ mu_2\n","\n","    # Смещение\n","    b = 0.5 * (mu1_S_inv_mu1 - mu2_S_inv_mu2) + log_prior_ratio\n","\n","    return b\n","\n","b = get_b(mu_1, mu_2, Sigma_inv, class_1_size, class_2_size)\n","assert np.isclose(b, -27.499753803149826)"],"metadata":{"id":"Q-wDLJ5yVZOk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Построение разделяющей прямой\n","x_vals = np.linspace(np.min(X[:, 0]), np.max(X[:, 0]), 100)\n","\n","# Координаты y для гиперплоскости\n","y_vals = -(w[0] * x_vals + b) / w[1]\n","\n","# Визуализация\n","plt.figure(figsize=(8,8))\n","plt.scatter(class_1[:, 0], class_1[:, 1], label='Class 1', c='blue', alpha=0.7)\n","plt.scatter(class_2[:, 0], class_2[:, 1], label='Class 2', c='red', alpha=0.7)\n","plt.plot(x_vals, y_vals, label='Разделяющая гиперплоскость', color='black', linestyle = \"--\")\n","plt.legend()\n","plt.title('Разделяющая поверхность: $\\\\Sigma_1 = \\\\Sigma_2$')\n","plt.xlabel('Признак 1')\n","plt.ylabel('Признак 2')\n","plt.axis('scaled')\n","plt.show()"],"metadata":{"id":"ktFdszg4bHGQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Если к данным добавить фиктивный столбец из единиц и в начало вектора весов добавить коэффициент, отвечающий за смещение, то классификатор будет выглядеть следующим образом"],"metadata":{"id":"VHC_JX8BugPj"}},{"cell_type":"code","source":["X_stacked = np.hstack((np.array([1]*len(X)).reshape(-1,1), X))\n","W_stacked = np.hstack((b,w))\n","\n","def predict(sample, W):\n","    result = sample @ W\n","    if result < 0:\n","        return 1\n","    return 2"],"metadata":{"id":"HPj5zKV1vp_r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Тестовый объект 1\n","sample_1 = np.array([1,3,2])\n","# Предсказание класса\n","predict(sample_1, W_stacked)"],"metadata":{"id":"X9kCeFfhxJ8Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Тестовый объект 2\n","sample_2 = np.array([1,6,5])\n","# Предсказание класса\n","predict(sample_2, W_stacked)"],"metadata":{"id":"indO5A_RxWer"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Визуализация\n","plt.figure(figsize=(8,8))\n","plt.scatter(class_1[:, 0], class_1[:, 1], label='Class 1', c='blue', alpha=0.2)\n","plt.scatter(class_2[:, 0], class_2[:, 1], label='Class 2', c='red', alpha=0.2)\n","plt.scatter(sample_1[1], sample_1[2], s=100, c='blue')\n","plt.scatter(sample_2[1], sample_2[2], s=100, c='red')\n","plt.plot(x_vals, y_vals, label='Разделяющая гиперплоскость', color='black', linestyle = \"--\")\n","plt.legend()\n","plt.title('Разделяющая поверхность: $\\\\Sigma_1 = \\\\Sigma_2$')\n","plt.xlabel('Признак 1')\n","plt.ylabel('Признак 2')\n","plt.axis('scaled')\n","plt.show()"],"metadata":{"id":"x-OirrQUWpFJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# QDA"],"metadata":{"id":"0ltKde4Q1Mon"}},{"cell_type":"markdown","source":["Напомним выражение для резделяющей поверхности:\n","\n","$$\n","\\ln \\mathbb{P}(C_1) - \\frac{1}{2}\\ln |\\Sigma_1| - \\frac{1}{2}(x-\\mu_1)^{T}\\Sigma_1^{-1}(x-\\mu_1) = \\ln \\mathbb{P}(C_2) - \\frac{1}{2}\\ln |\\Sigma_2| - \\frac{1}{2}(x-\\mu_2)^{T}\\Sigma_2^{-1}(x-\\mu_2).\n","$$\n","\n","Будем называть каждую из частей уравнения **дискриминантной функцией** класса $1$ и $2$ соответственно."],"metadata":{"id":"rXf_eeCm1VRx"}},{"cell_type":"code","source":["# Генерация данных\n","np.random.seed(42)\n","\n","class_1_size = 100\n","class_2_size = 100\n","\n","class_1 = np.random.multivariate_normal(mean=[2, 2], cov=[[1, 0.5], [0.5, 1]], size=class_1_size)\n","class_2 = np.random.multivariate_normal(mean=[5, 5], cov=[[1, -0.5], [-0.5, 1]], size=class_2_size)\n","\n","# Объединение данных\n","X = np.vstack((class_1, class_2))\n","y = np.hstack((np.zeros(100), np.ones(100)))\n","\n","# Визуализация данных\n","plt.figure(figsize=(8,8))\n","plt.scatter(class_1[:, 0], class_1[:, 1], label='Class 1', c='blue', alpha=0.7)\n","plt.scatter(class_2[:, 0], class_2[:, 1], label='Class 2', c='red', alpha=0.7)\n","plt.legend()\n","plt.title('Исходные данные двух классов')\n","plt.xlabel('Признак 1')\n","plt.ylabel('Признак 2')\n","plt.axis('scaled')\n","plt.show()"],"metadata":{"id":"sx_gL3gkE-zk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Вычисление параметров модели"],"metadata":{"id":"T3pHxGYQlt6h"}},{"cell_type":"code","source":["# Оценка среднего\n","def get_mu(class_objects):\n","    \"\"\"\n","    Параметры\n","    ----------\n","    class_objects : {array-like} формы (n_samples, n_features)\n","        Объекты одного класса, где `n_samples` — число объектов\n","        и `n_features` — число признаков.\n","\n","    Что возвращается\n","    -------\n","    mu : вектор из координат центроида класса\n","    \"\"\"\n","    return np.mean(class_objects, axis=0)\n","\n","\n","mu_1 = get_mu(class_1)\n","mu_2 = get_mu(class_2)\n","assert np.isclose(mu_1, np.array([2.08307042, 2.11709274])).all() and np.isclose(mu_2, np.array([4.91067717, 5.13281048])).all()"],"metadata":{"id":"DXFMwgzLFHxo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Внутриклассовая матрица ковараций\n","def get_Sigma(class_elements, mu):\n","    \"\"\"\n","    Параметры\n","    ----------\n","    class_elements : {array-like} формы (n_samples, n_features)\n","        Объекты данного класса, где `n_samples` — число объектов\n","        и `n_features` — число признаков.\n","    mu : {numpy.ndarray} — вектор из координат центроида данного класса\n","\n","    Что возвращается\n","    -------\n","    Sigma : матрица ковариаций данного класса\n","    \"\"\"\n","    centered = class_elements - mu       # центрирование\n","    n = centered.shape[0]                # число объектов\n","    return (centered.T @ centered) / n\n","\n","Sigma_1 = get_Sigma(class_1, mu_1)\n","Sigma_2 = get_Sigma(class_2, mu_2)\n","assert np.isclose(Sigma_1, np.array([[0.8150929 , 0.29751939],[0.29751939, 0.76768711]])).all() and np.isclose(Sigma_2, np.array([[ 1.08836645, -0.58617111], [-0.58617111,  0.94906895]])).all()"],"metadata":{"id":"IfQyO858FIMS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Оценка вероятностей классов\n","def get_prior(class_1, class_2):\n","    \"\"\"\n","    Параметры\n","    ----------\n","    class_1 : {array-like} формы (n_samples, n_features)\n","        Объекты класса 1, где `n_samples` — число объектов\n","        и `n_features` — число признаков.\n","    class_2 : {array-like} формы (n_samples, n_features)\n","        Объекты класса 2, где `n_samples` — число объектов\n","        и `n_features` — число признаков.\n","\n","    Что возвращается\n","    -------\n","    (prior_1, prior_2) : кортеж, состоящий из оценок вероятностей классов 1 и 2\n","    \"\"\"\n","    n1 = len(class_1)\n","    n2 = len(class_2)\n","    total = n1 + n2\n","    return (n1 / total, n2 / total)\n","\n","prior_1, prior_2 = get_prior(class_1, class_2)\n","assert np.isclose(np.array([prior_1, prior_2]), np.array([0.5, 0.5])).all()"],"metadata":{"id":"oF8ryTJiGMZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Вычисление дискриминантной функции\n","def get_discriminant(x, Sigma, mu, prior):\n","    \"\"\"\n","    Параметры\n","    ----------\n","    x : {array-like} вектор n_features\n","        Один объект данных, где `n_features` — число признаков.\n","    Sigma : матрица ковариаций данного класса\n","    mu : {numpy.ndarray} — вектор из координат центроида данного класса\n","    prior : оценка вероятности данного класса\n","\n","    Что возвращается\n","    -------\n","    discriminant : значение дискриминантной функции для данного класса в точке x\n","    \"\"\"\n","    x = np.array(x)\n","    mu = np.array(mu)\n","    diff = x - mu\n","\n","    # Обращение матрицы и определитель\n","    Sigma_inv = np.linalg.inv(Sigma)\n","    det_Sigma = np.linalg.det(Sigma)\n","\n","    # Логарифм априорной вероятности\n","    log_prior = np.log(prior)\n","\n","    # Логарифм определителя\n","    log_det = np.log(det_Sigma)\n","\n","    # Квадратичная форма (скаляр)\n","    exponent = diff @ Sigma_inv @ diff\n","\n","    # Дискриминантная функция\n","    discriminant = log_prior - 0.5 * log_det - 0.5 * exponent\n","\n","    return discriminant\n","\n","assert np.isclose(get_discriminant(X[0], Sigma_1, mu_1, prior_1), -0.6600206493124732)"],"metadata":{"id":"1E6aR_xMGXDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Создание сетки для визуализации разделяющей поверхности\n","x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n","y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n","xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n","\n","# Вычисление квадратичного уравнения для каждой точки сетки\n","Z = np.zeros_like(xx)\n","for i in tqdm(range(xx.shape[0])):\n","    for j in range(xx.shape[1]):\n","        x = np.array([xx[i, j], yy[i, j]])\n","\n","        # Разница дискриминантных функций\n","        Z[i, j] = get_discriminant(x, Sigma_1, mu_1, prior_1) - get_discriminant(x, Sigma_2, mu_2, prior_2)\n","\n","# Построение графика разделяющей кривой\n","plt.figure(figsize=(8,8))\n","plt.contourf(xx, yy, Z, levels=0, cmap=ListedColormap(['#FFAAAA', '#AAAAFF']), alpha=0.5)\n","plt.contour(xx, yy, Z, levels=[0], colors='black')\n","plt.scatter(class_1[:, 0], class_1[:, 1], label='Class 1', c='blue', alpha=0.7)\n","plt.scatter(class_2[:, 0], class_2[:, 1], label='Class 2', c='red', alpha=0.7)\n","plt.legend()\n","plt.title('Разделяющая поверхность: $\\\\Sigma_1 \\\\neq \\\\Sigma_2$')\n","plt.xlabel('Признак 1')\n","plt.ylabel('Признак 2')\n","plt.show()"],"metadata":{"id":"t84QgD60Gvfv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SVM"],"metadata":{"id":"a6B0XAZYuz_U"}},{"cell_type":"markdown","source":["Реализуйте `kernel SVM` с ипользованием пакета `optimize` с использованием полиномиального ядра. Продемонстрируйте результаты, сравните с библиотечным вариантом, на наборе данных типа концентрических окружностей"],"metadata":{"id":"3eWqE0NSXrDa"}},{"cell_type":"code","source":["# Генерация данных: концентрические окружности\n","X, y = make_circles(n_samples=100, noise=0.1, factor=0.3, random_state=42)\n","y = 2 * y - 1  # переводим метки в -1 и +1\n","\n","# Нормализуем данные\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)"],"metadata":{"id":"ybtr1IMI8pvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. Полиномиальное ядро\n","def polynomial_kernel(X1, X2, degree=2, gamma=1, coef=0):\n","    return (gamma * np.dot(X1, X2.T) + coef) ** degree\n","\n","# 2. Решение двойственной задачи с помощью scipy.optimize\n","def train_kernel_svm(X, y, kernel_func, C=1.0, **kernel_params):\n","    n_samples = X.shape[0]\n","\n","    # Вычисляем матрицу ядра\n","    K = kernel_func(X, X, **kernel_params)\n","\n","    # Умножаем на y_i * y_j\n","    P = y[:, None] * y[None, :] * K  # матрица для целевой функции\n","\n","    # Целевая функция: 0.5 * alpha^T P alpha - sum(alpha)\n","    def objective(alpha):\n","        return 0.5 * alpha @ P @ alpha - np.sum(alpha)\n","\n","    # Градиент\n","    def grad_objective(alpha):\n","        return P @ alpha - 1\n","\n","    # Ограничения\n","    # Условие: y^T @ alpha = 0\n","    A = y.reshape(1, -1)\n","    constraints = {'type': 'eq', 'fun': lambda alpha: A @ alpha, 'jac': lambda alpha: A}\n","\n","    # Ограничения: 0 <= alpha <= C\n","    bounds = [(0, C) for _ in range(n_samples)]\n","\n","    # Начальное приближение\n","    alpha0 = np.zeros(n_samples)\n","\n","    # Решаем\n","    result = minimize(objective, alpha0, method='SLSQP', bounds=bounds,\n","                      constraints=constraints, jac=grad_objective, options={'disp': False})\n","\n","    alpha = result.x\n","\n","    # Находим опорные векторы\n","    sv_idx = (alpha > 1e-5)\n","    alpha_sv = alpha[sv_idx]\n","    X_sv = X[sv_idx]\n","    y_sv = y[sv_idx]\n","\n","    # Вычисляем b\n","    # используем среднее по опорным векторам\n","    K_sv = kernel_func(X_sv, X_sv, **kernel_params)\n","    b = np.mean(y_sv - (alpha_sv * y_sv) @ K_sv)\n","\n","    return alpha_sv, X_sv, y_sv, b, sv_idx\n","\n","# 3. Предсказание\n","def predict_kernel_svm(X_test, X_sv, y_sv, alpha_sv, b, kernel_func, **kernel_params):\n","    K_test = kernel_func(X_test, X_sv, **kernel_params)\n","    y_pred = K_test @ (alpha_sv * y_sv) + b\n","    return np.sign(y_pred), y_pred"],"metadata":{"id":"DCaUFqh_6YZt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Параметры ядра\n","kernel_params = {'degree': 2, 'gamma': 1, 'coef': 0}\n","\n","# Обучение модели\n","alpha_sv, X_sv, y_sv, b, sv_idx = train_kernel_svm(X_scaled, y, polynomial_kernel, C=1.0, **kernel_params)\n","\n","# Предсказания\n","y_pred_ours, _ = predict_kernel_svm(X_scaled, X_sv, y_sv, alpha_sv, b, polynomial_kernel, **kernel_params)\n","acc_ours = accuracy_score(y, y_pred_ours)\n","\n","# Сравнение с sklearn\n","clf_sklearn = SVC(kernel='poly', degree=2, gamma=1, coef0=0, C=1.0)\n","clf_sklearn.fit(X_scaled, y)\n","y_pred_sk = clf_sklearn.predict(X_scaled)\n","acc_sk = accuracy_score(y, y_pred_sk)"],"metadata":{"id":"qX0pl3YA80LK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Визуализация\n","def plot_decision_boundary(X, y, model=None, sklearn_model=None, scaler=None):\n","    h = 0.01\n","    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n","    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n","                         np.arange(y_min, y_max, h))\n","    grid = np.c_[xx.ravel(), yy.ravel()]\n","\n","    if scaler:\n","        grid = scaler.transform(grid)\n","\n","    if model == 'our_svm':\n","        Z, _ = predict_kernel_svm(grid, X_sv, y_sv, alpha_sv, b, polynomial_kernel, **kernel_params)\n","    elif sklearn_model:\n","        Z = sklearn_model.predict(grid)\n","    Z = Z.reshape(xx.shape)\n","\n","    plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.RdYlBu)\n","    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, edgecolors='k')\n","    plt.title(\"Разделяющая поверхность\")\n","    plt.xlabel(\"Признак 1\")\n","    plt.ylabel(\"Признак 2\")\n","\n","plt.figure(figsize=(14, 6))\n","\n","# Моя модель\n","plt.subplot(1, 2, 1)\n","plot_decision_boundary(X, y, model='our_svm', scaler=scaler)\n","plt.title(f\"Моя реализация SVM (точность: {acc_ours:.2f})\")\n","\n","# Sklearn\n","plt.subplot(1, 2, 2)\n","plot_decision_boundary(X, y, sklearn_model=clf_sklearn, scaler=scaler)\n","plt.title(f\"Sklearn SVM (точность: {acc_sk:.2f})\")\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"2TzBsuFn9BgS"},"execution_count":null,"outputs":[]}]}