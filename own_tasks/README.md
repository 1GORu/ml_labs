# Churn.ipynb

> Решение задачи классификации оттока клиентов в рамках соревнования (метрика: **ROC-AUC**).

---

## Контекст
Большинство участников достигали ROC-AUC ≈ **0.846** с логистической регрессией.  
После предобработки данных и отбора признаков мне удалось поднять результат до **0.853**.

Многие использовали CatBoost с автоматическим подбором гиперпараметров и получали ROC-AUC ≈ **0.856**.  
Я применил CatBoost, задав вручную ключевые, на мой взгляд, параметры — результат оказался практически сопоставим с лучшими публичными решениями.

Что касается самих данных, они, похоже, не обладают выраженной нелинейностью — поэтому линейная модель почти не уступает бустингу на деревьях.

В лидерборде встречаются значения ROC-AUC до **0.99**, достигнутые с помощью полносвязных нейросетей. Однако в открытом доступе циркулирует полный датасет, включая тестовую часть, что почти наверняка указывает на **data leak**: тестовые данные попали в обучающую выборку. Такие решения не обобщаются и не имеют практической ценности.

Я отказался от стекинга, так как считаю его избыточным для большинства индустриальных задач: такие ансамбли сложно интерпретировать, поддерживать в продакшене и объяснять заинтересованным сторонам.
