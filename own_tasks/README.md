## Churn.ipynb

> Решение задачи классификации оттока клиентов в рамках соревнования (метрика: **ROC-AUC**).

### Описание

Большинство участников достигали ROC-AUC ≈ 0.846 с `логистической регрессией`. После предобработки данных и отбора признаков мне удалось поднять результат до 0.853.

Многие использовали `CatBoost` с автоматическим подбором гиперпараметров и получали ROC-AUC ≈ 0.856. Я применил CatBoost, задав вручную ключевые, на мой взгляд, параметры — результат оказался практически сопоставим с лучшими публичными решениями.

Что касается самих `данных`, они, похоже, не обладают выраженной нелинейностью — поэтому линейная модель почти не уступает бустингу на деревьях.

Я отказался от `стекинга`, так как считаю его избыточным для большинства индустриальных задач: такие ансамбли сложно интерпретировать, поддерживать в продакшене и объяснять заинтересованным сторонам.

В лидерборде встречаются значения ROC-AUC до 0.99, достигнутые с помощью `полносвязных нейросетей`. Однако в открытом доступе циркулирует полный датасет, включая тестовую часть, что почти наверняка указывает на `data leak`.

---
<br>

## ADR_prediction.ipynb

> Прогнозирование средней стоимости номера (ADR) в отелях центрального Чикаго на 6 месяцев вперёд с помощью линейной регрессии.

### Описание

Данные: ежемесячная статистика по отелям Chicago Central Business District за 1994–2003 гг.  
Целевая переменная — Average Daily Rate (ADR), усреднённая по всем отелям и дням каждого месяца.

Несмотря на простоту, линейная регрессия достаточно хорошо улавливает общую динамику и сезонность временного ряда, хотя и не воспроизводит пики идеально.

**Вывод:** даже простая линейная модель может быть эффективна в задачах временных рядов, если данные содержат чёткую сезонность и тренд — без необходимости прибегать к сложным методам вроде нейросетей или ARIMA.

---
<br>

## NaiveBayes_spam.ipynb

> Классификация SMS-сообщений на спам и не-спам.

### Описание

Использован классический датасет на английском языке с ручной разметкой (ham / spam).

Модель построена на наивном байесовском классификаторе — простом, быстром и проверенном методе для работы с текстами. В учебных курсах его часто приводят как эталонный пример фильтрации спама, но редко дают попрактиковаться. Этот ноутбук — попытка самостоятельно разобраться, как он устроен и насколько хорошо справляется с реальной задачей.

---
<br>

## Customer_segmentation_lollipops.ipynb

> Сегментация потребителей леденцов по целям употребления.

### Описание

Задача — выделить группы потребителей на основе их ответов на 11 утверждений о причинах употребления леденцов. 

Использованы два метода кластеризации: `иерархическая кластеризация (Ward)` и `DBSCAN`. 
Оба метода дали схожие результаты — что говорит о стабильности выявленных сегментов.

---
