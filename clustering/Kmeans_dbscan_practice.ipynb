{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from sklearn.cluster import DBSCAN\n","from tqdm.notebook import tqdm\n","from sklearn.datasets import make_moons\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_blobs\n","import numpy as np\n","from sklearn.cluster import KMeans\n","plt.style.use('ggplot')"],"metadata":{"id":"mO6JwVknhph0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# K-means"],"metadata":{"id":"UK8v9mNCC0S8"}},{"cell_type":"markdown","source":["## Теоретическая справка"],"metadata":{"id":"IoUNd9lSif6o"}},{"cell_type":"markdown","source":["Здесь нужно вставить теорию про inertia какая вообще идея в кластеризации типа уменьшение внутрикластерного расстояния, определение, что это такое и тп. Формулы, что внутрикластерное расстояние эквивалентно сумме растояний от объектов до соответствующих центроидов (вывод эквивалентности формул при использовании квадрата евклидова расстояния).\n","\n","Сам алгоритм k-means.\n","\n","Доказательство сходимости к локальному оптимуму (что на каждой итерации целевое значение не ухудшается при использовании квадрата евклидова расстояния) по шагам алгоритма."],"metadata":{"id":"o5Z7Ftjpii5g"}},{"cell_type":"markdown","source":["Пусть $X =\\{x_1, x_2, ..., x_n\\}$ -- множество рассматриваемых объектов, $C_1, C_2, ..., C_K$ -- разбиение $X$, $d$ -- функция расстояния, заданная на $X$.\n","\n","Внутрикластерным расстоянием $W(C_k)$ в кластере $C_k$ называют сумму попарных расстояний между всеми объектами этого кластера, то есть\n","\n","$$\n","W\\left(C_{k}\\right)=\\sum_{x_i, x_{i^{\\prime}} \\in C_{k}} d \\left(x_{i}, x_{i^{\\prime}}\\right), \\quad k \\in \\{1, 2, ..., K\\}.\n","$$\n","\n","В обозначениях предыдущего определения, средним внутрикластерным расстоянием в кластере $C_k$ называется величина, равная\n","$$\n","\\frac{W\\left(C_{k}\\right)}{\\left|C_{k}\\right|}, \\quad k \\in \\{1, 2, ..., K\\},\n","$$\n","где $\\left|C_{k}\\right|$ -- количество объектов, принадлежащих кластеру $C_{k}$."],"metadata":{"id":"QcKM8m3hxsCZ"}},{"cell_type":"markdown","source":["Чтобы минимизировать средние внутрикластерные расстояния, можно попробовать минимизировать их сумму по всем кластерам, то есть минимизировать следующее выражение:\n","\n","$$\n","\\sum_{k=1}^{K}\\frac{W\\left(C_{k}\\right)}{\\left|C_{k}\\right|} = \\sum_{k=1}^{K} \\frac{1}{\\left|C_{k}\\right|}\\sum_{x_i, x_{i^{\\prime}} \\in C_{k}} d \\left(x_{i}, x_{i^{\\prime}}\\right).\n","$$\n","\n","В качестве функции расстояния будем использовать не евклидово расстояние, а его квадрат. При таком выборе функции расстояния близкие объекты (евклидово расстояние между которыми меньше единицы) вносят меньший вклад в минимизируемую сумму, а далекие (евклидово расстояние между которыми больше единицы) -- больший. Само минимизируемое выражение выглядит следующим образом:\n","\n","$$\n","\\sum_{k=1}^{K} \\frac{1}{\\left|C_{k}\\right|}\\sum_{x_i, x_{i^{\\prime}} \\in C_{k}} d_E ^2\\left(x_{i}, x_{i^{\\prime}}\\right).\n","$$\n","\n","И последний технический, но важный аспект\n","\n","Оказывается, при использовании в качестве функции расстояния квадрата евклидова расстояния, справедливо следующее равенство\n","\n","$$\n","\\frac{1}{|C_{k} |} \\sum_{x_i,x_{i^{\\prime}}\\in C_{k}} d_E^2(x_i, x_{i'}) = 2 \\sum_{x_i \\in C_{k}} d_E^2(x_i, \\overline{x}_k),\n","$$\n","\n","где $\\overline{x}_k$ — центроид кластера $k$."],"metadata":{"id":"ZNWv4y_Ix4KS"}},{"cell_type":"markdown","source":[],"metadata":{"id":"wb0B-0iLCy61"}},{"cell_type":"markdown","source":["Итак, пришло время сформулировать алгоритм применения метода K-средних. Пусть имеется набор данных $X = (x_1, x_2, ..., x_n)$ объема $n$ с числовыми признаками, где\n","\n","$$\n","x_i = (x_{i1}, x_{i2}, ..., x_{ip}), \\quad i \\in \\{1, 2, ..., n\\}.\n","$$\n","\n","*    Выбирается число $K \\in \\mathbb N$.\n","\n","*    $\\textbf{Инициализация.}$ Каждый объект случайным образом относят к какому-то кластеру из набора $C_1, C_2, ..., C_K$.\n","\n","*    $\\textbf{Нахождение центроидов.}$ Для каждого кластера $C_k$ находят координаты центроида:\n","\n","$$\n","\\overline x_k = (\\overline x_{k1}, \\overline x_{k2}, ..., \\overline x_{kp}), \\quad\n","\\overline{x}_{k j}=\\frac{1}{\\left|C_{k}\\right|}\\sum_{x_i \\in C_{k}} x_{i j},\n","$$\n","\n","где $k \\in \\{1, 2, \\dots, K \\}, \\ j \\in \\{1, 2, \\dots, p\\}$.\n","\n","*    $\\textbf{Вычисление квадратов расстояний до центроидов.}$ Находят квадрат евклидова расстояния от $i$-го объекта до центроида каждого кластера:\n","\n","$$\n","d_E^2(x_i, \\overline{x}_k)=\\sum_{j=1}^{p}\\left(x_{i j}-\\overline{x}_{k j}\\right)^{2},$$\n","$$ k \\in \\{1, 2, \\dots, K \\}, \\quad i \\in \\{1, 2, \\dots, n \\}.\n","$$\n","\n","*    $\\textbf{Перераспределение.}$ Объект $x_i$ относят к кластеру с наиболее близким к нему центроидом, то есть $x_i \\in C_{k^*}$, где $k^\\ast$ -- любое из решений задачи\n","\n","$$\n","\\text{Argmin}_{k \\in \\{1, 2, ..., K\\}} d_E^2(x_i, \\overline{x}_k).\n","$$\n","\n","Отметим, что если среди решений поставленной задачи есть номер текущего кластера, то объект не меняет своей кластерной принадлежности.\n","\n","*    Шаги $2$ -- $6$ повторяются, пока объекты не перестанут перераспределяться по кластерам"],"metadata":{"id":"81OXR3urzuEh"}},{"cell_type":"markdown","source":["## Генерация датасета"],"metadata":{"id":"bvBlIAc9Vh49"}},{"cell_type":"code","source":["n_centers = 3\n","n_dots = 100\n","n_samples = n_centers * n_dots\n","random_state = 42\n","\n","X, y = make_blobs(n_samples=n_samples, random_state=random_state, centers=n_centers, center_box=(-5.0, 5.0))\n","\n","plt.figure(figsize=(10, 8))\n","plt.scatter(X[:,0], X[:,1])\n","plt.show()"],"metadata":{"id":"yAnILUpDVjrz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Реализация метода вручную"],"metadata":{"id":"gekhWE33WhXT"}},{"cell_type":"code","source":["# Число k\n","k = 3"],"metadata":{"id":"Kt_vQWs23EV_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Инициализация меток кластеров"],"metadata":{"id":"K0utYoxmWsbq"}},{"cell_type":"code","source":["def initialize_randomly(random_state, X, k):\n","    \"\"\"\n","    Инициализирует метки кластеров (от 0 до k не включительно)\n","    случайным образом при помощи np.random.randint\n","\n","    Args:\n","        random_state (int):  Зерно для генератора случайных чисел (np.random.seed()).\n","        X (ndarray): Массив данных (форма n_samples, n_features).\n","        k (int): Количество кластеров.\n","\n","    Returns:\n","        ndarray: Массив меток кластеров для каждой точки данных (форма n_samples,).\n","    \"\"\"\n","    np.random.seed(random_state)\n","    n_samples = X.shape[0]\n","    labels = np.random.randint(0, k, size=n_samples)\n","    return labels\n","\n","assert np.equal(initialize_randomly(random_state, X, k)[:10], np.array([2, 0, 2, 2, 0, 0, 2, 1, 2, 2])).all()"],"metadata":{"id":"pExe1gqsWl4L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clusters = initialize_randomly(random_state, X, k)"],"metadata":{"id":"8mD6Chqh2QKz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Нахождение центроидов"],"metadata":{"id":"a74l_aIcdJO8"}},{"cell_type":"code","source":["def get_centroids(X, clusters):\n","    \"\"\"\n","    Вычисляет центроиды для каждого кластера.\n","\n","    Args:\n","        X (ndarray): Массив данных (форма n_samples, n_features).\n","        clusters (ndarray): Массив меток кластеров для каждой точки данных (форма n_samples,).\n","\n","    Returns:\n","        ndarray: Массив координат центроидов (форма k, n_features).\n","    \"\"\"\n","    k = len(np.unique(clusters))  # Определяем количество кластеров\n","    n_features = X.shape[1]\n","    centroids = np.zeros((k, n_features))\n","\n","    for cluster_label in range(k):\n","        # Выбираем все точки, принадлежащие текущему кластеру\n","        points_in_cluster = X[clusters == cluster_label]\n","        # Вычисляем среднее по каждой фиче — это и есть центроид\n","        centroids[cluster_label] = points_in_cluster.mean(axis=0)\n","\n","    return centroids\n","\n","assert np.isclose(get_centroids(X, clusters), np.array([[-1.03358594,  0.73421037], [-1.02480976,  0.14279789], [-0.38220266,  1.07982105]])).all()"],"metadata":{"id":"CyWrzi2WYJ1p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["centroids = get_centroids(X, clusters)"],"metadata":{"id":"j5ZgdiSJ2h5O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Вычисление квадратов расстояний до центроидов"],"metadata":{"id":"EJ7Jp71lcZoP"}},{"cell_type":"code","source":["def squared_euclidean_distance(obj, centroids):\n","    \"\"\"\n","    Вычисляет квадрат евклидова расстояния между точкой данных и каждым центроидом.\n","\n","    Args:\n","        obj (ndarray): Точка данных (форма n_features,).\n","        centroids (ndarray): Массив центроидов (форма k, n_features).\n","\n","    Returns:\n","        ndarray: Массив квадратов евклидовых расстояний между точкой данных и каждым центроидом (форма k,).\n","    \"\"\"\n","    # Вычисляем разницу между точкой и каждым центроидом: (x - μ_i)\n","    diff = obj - centroids  # форма: (k, n_features)\n","\n","    # Квадрат евклидова расстояния — это сумма квадратов разностей по каждой фиче\n","    squared_distances = np.sum(diff ** 2, axis=1)  # суммируем по признакам (axis=1)\n","\n","    return squared_distances\n","\n","assert np.isclose(squared_euclidean_distance(X[0], centroids), np.array([33.45327436, 27.91077581, 41.20298604])).all()"],"metadata":{"id":"KHHcpJjycdOG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Основной цикл"],"metadata":{"id":"1NLeVPN3d4Dv"}},{"cell_type":"code","source":["def kmeans_algorithm(X, k, random_state, max_iter=1000):\n","    \"\"\"\n","    Реализует алгоритм K-means. Если алгоритм не сошелся за max_iter, вывести\n","    соответствующее оповещение на экран.\n","\n","    Args:\n","        X (ndarray): Массив данных (форма n_samples, n_features).\n","        k (int): Количество кластеров.\n","        random_state (int): Зерно для генератора случайных чисел.\n","        max_iter (int): Максимальное количество итераций.\n","\n","    Returns:\n","        tuple: Кортеж, содержащий:\n","            - ndarray: Массив меток кластеров для каждой точки данных (форма n_samples,).\n","            - int: Шаг, на котором сошелся алгоритм.\n","    \"\"\"\n","\n","    # Инициализация меток кластеров случайным образом\n","    clusters = initialize_randomly(random_state, X, k)\n","\n","    # Предыдущие метки для проверки сходимости\n","    prev_clusters = np.copy(clusters)\n","\n","    # Выполняем итерации до max_iter\n","    for step in range(max_iter):\n","        # Пересчитываем центроиды по текущим кластерам\n","        centroids = get_centroids(X, clusters)\n","\n","        # Назначаем каждую точку ближайшему центроиду\n","        for i in range(X.shape[0]):\n","            # Вычисляем квадраты расстояний от точки до центроидов\n","            distances = squared_euclidean_distance(X[i], centroids)\n","            # Назначаем точку кластеру с минимальным расстоянием\n","            clusters[i] = np.argmin(distances)\n","\n","        # Проверяем сходимость: если метки не изменились — алгоритм сошёлся\n","        if np.array_equal(clusters, prev_clusters):\n","            return clusters, step + 1  # возвращаем кластеры и номер шага\n","\n","        # Обновляем предыдущие метки\n","        prev_clusters = np.copy(clusters)\n","\n","    # Если не сошёлся за max_iter итераций\n","    print(\"Алгоритм не сошелся за максимальное количество итераций.\")\n","    return clusters, max_iter"],"metadata":{"id":"ai54axQ3d3X_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clusters, conv_iter = kmeans_algorithm(X, k, random_state, max_iter=1000)\n","print('Converged at iteration {}'.format(conv_iter))"],"metadata":{"id":"5s6c-q9MgEIs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n","ax1.scatter(X[:, 0], X[:, 1], c=y)\n","ax1.set_title('Data Generation')\n","ax2.scatter(X[:, 0], X[:, 1], c=clusters)\n","ax2.set_title('K-means (Numpy)')\n","plt.show()"],"metadata":{"id":"bdrI1Lif76ot"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Инициализация через центроиды и библиотечная реализация"],"metadata":{"id":"YuAP3vgaje4a"}},{"cell_type":"code","source":["def initialize_centroids(X,k,random_state):\n","    \"\"\"\n","    Инициализирует центроиды случайными точками из пространства данных.\n","    Сначала установить зерно генератора np.random.seed, затем, используя\n","    np.random.random_sample, сгенерировать массив координат центроидов\n","\n","    Args:\n","        X (ndarray): Массив данных (форма n_samples, n_features).\n","        k (int): Количество кластеров.\n","        random_state (int): Зерно для генератора случайных чисел.\n","\n","    Returns:\n","        ndarray: Массив центроидов (форма k, n_features).\n","    \"\"\"\n","    np.random.seed(random_state)\n","    n_features = X.shape[1]\n","    # Генерируем k точек\n","    centroids = np.random.random_sample((k, n_features))\n","    return centroids\n","\n","assert np.isclose(initialize_centroids(X,k,random_state), np.array([[0.37454012, 0.95071431], [0.73199394, 0.59865848], [0.15601864, 0.15599452]])).all()"],"metadata":{"id":"HCWDEiuYjp_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def kmeans_algorithm(X, k, random_state, max_iter=1000):\n","    \"\"\"\n","    Реализует алгоритм K-means. Если алгоритм не сошелся за max_iter, вывести\n","    соответствующее оповещение на экран.\n","\n","    Args:\n","        X (ndarray): Массив данных (форма n_samples, n_features).\n","        k (int): Количество кластеров.\n","        random_state (int): Зерно для генератора случайных чисел.\n","        max_iter (int): Максимальное количество итераций.\n","\n","    Returns:\n","        tuple: Кортеж, содержащий:\n","            - ndarray: Массив меток кластеров для каждой точки данных (форма n_samples,).\n","            - int: Шаг, на котором сошелся алгоритм.\n","    \"\"\"\n","    # Устанавливаем seed для воспроизводимости\n","    np.random.seed(random_state)\n","\n","    # Инициализируем центроиды случайными точками\n","    centroids = initialize_centroids(X, k, random_state)\n","\n","    n_samples, n_features = X.shape\n","\n","    for step in range(max_iter):\n","        # Сохраняем предыдущие центроиды для проверки сходимости\n","        prev_centroids = np.copy(centroids)\n","\n","        # Назначаем каждой точке ближайший кластер\n","        clusters = np.zeros(n_samples, dtype=int)\n","        for i in range(n_samples):\n","            distances = squared_euclidean_distance(X[i], centroids)\n","            clusters[i] = np.argmin(distances)\n","\n","        # Пересчитываем центроиды как среднее по точкам кластера\n","        for j in range(k):\n","            cluster_points = X[clusters == j]\n","            if len(cluster_points) > 0:\n","                centroids[j] = cluster_points.mean(axis=0)\n","            # Если кластер пустой — оставляем центроид без изменений\n","\n","        # Проверяем сходимость: центроиды не изменились\n","        if np.allclose(centroids, prev_centroids):\n","            return clusters, step + 1  # сходимость достигнута\n","\n","    # Если не сошёлся за max_iter\n","    print(\"Алгоритм не сошелся за максимальное количество итераций.\")\n","    return clusters, max_iter"],"metadata":{"id":"odZw60iWkc4b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clusters, conv_iter = kmeans_algorithm(X, k, random_state, max_iter=1000)\n","print('Converged at iteration {}'.format(conv_iter))"],"metadata":{"id":"ylweohWc9gbe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Sklearn"],"metadata":{"id":"WoHtjVTHpTto"}},{"cell_type":"code","source":["kmeans = KMeans(n_clusters=3, init=initialize_centroids(X,k,random_state)).fit(X)\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n","ax1.scatter(X[:, 0], X[:, 1], c=clusters)\n","ax1.set_title('K-means (Numpy)')\n","ax2.scatter(X[:, 0], X[:, 1], c=kmeans.labels_)\n","ax2.set_title('K-means (Sklearn)')\n","plt.show()"],"metadata":{"id":"HDdBMcPZpVHz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DBSCAN"],"metadata":{"id":"6EbsZlQ5DJod"}},{"cell_type":"markdown","source":["## Теоретическая справка"],"metadata":{"id":"Fq8dGbScDMZG"}},{"cell_type":"markdown","source":["DBSCAN (Density-based spatial clustering of applications with noise) -- плотностный алгоритм пространственной кластеризации с присутствием шума. Если вдуматься в само название алгоритма, то становится понятной и идея: объекты составляют один и тот же кластер, если все они плотно расположены друг к другу. Что значит плотно? Это значит, что  рядом с каждым объектом кластера есть достаточно много соседей -- элементов этого же кластера."],"metadata":{"id":"NQeHRxroDO7s"}},{"cell_type":"markdown","source":["DBSCAN справляется с нахождением как плотных шаровых сгустков, так и ленточных кластеров. При фиксированных параметрах модели количество кластеров определяется однозначным образом.\n","\n","**Основные определения:**\n","\n","Пусть $X = (x_1, x_2, ..., x_n)$ - набор данных объема $n$, где $x_i \\in \\mathbb{R}^p$ (каждый объект описывается $p$ числовыми признаками).  Пусть $d$ - выбранная функция расстояния в $\\mathbb{R}^p$.\n","\n","*   **Замкнутый шар:** Пусть $\\varepsilon > 0$. Множество\n","    \n","    $$\n","    \\overline{B}(x_0, \\varepsilon) = \\{y \\in X: \\ d(x_0, y) \\leq \\varepsilon\\}\n","    $$\n","\n","    называется замкнутым шаром в $X$ с центром в $x_0$ и радиуса $\\varepsilon$.  $|\\overline{B}(x_0, \\varepsilon)|$ - количество элементов в множестве $\\overline{B}(x_0, \\varepsilon)$.\n","\n","*   **Соседи:** Пусть $\\varepsilon > 0$. Элементы множества $\\overline{B}(x_0, \\varepsilon)$ называются соседями элемента $x_0$.  Предполагается, что функция расстояния $d$ обладает свойствами $d(x, x) = 0$ и $d(x, x') = d(x', x)$.\n","\n","*   **Корневой объект:** Пусть $m \\in \\mathbb{N}$ - некоторое наперед заданное число. Если\n","\n","    $$\n","    |\\overline{B}(x_0, \\varepsilon)| \\geq m,\n","    $$\n","\n","    то объект $x_0$ называется корневым объектом.\n","\n","*   **Граничный объект (граничная точка):** Некорневой объект, не являющийся выбросом. Граничные объекты могут менять свою кластерную принадлежность при перезапуске алгоритма даже с неизменными параметрами.\n","\n","**Алгоритм DBSCAN:**\n","\n","1.  Выбираются $\\varepsilon > 0$ и $m \\in \\mathbb{N}$. Пусть $i = 1$.\n","2.  Находится какой-нибудь корневой объект $x$ в $X$. Если таковых нет, то производится переход к пункту 7.\n","3.  Все соседи объекта $x$ помещаются в кластер $C_i$.\n","4.  Для каждого элемента из $C_i$ проверяется, является ли он корневым. Если является, то все соседи найденного корневого элемента добавляются к $C_i$.\n","5.  Пункт 4 повторяется до тех пор, пока состав кластера $C_i$ не перестанет изменяться.\n","6.  Полагается $X = X \\setminus C_i$, $i = i + 1$. Производится переход к пункту 2.\n","7.  Все объекты множества $X$, если они есть, помещаются в отдельный кластер - выбросы. Кластеризация завершена."],"metadata":{"id":"Zp4nfvfoDcqg"}},{"cell_type":"markdown","source":["## Генерация данных"],"metadata":{"id":"MksCbdxxEr-s"}},{"cell_type":"code","source":["# Создадим датасет в форме полумесяцев, чтобы показать возможности DBSCAN\n","X, y = make_moons(n_samples=200, noise=0.05, random_state=42)\n","\n","plt.figure(figsize=(10, 8))\n","plt.scatter(X[:,0], X[:,1])\n","plt.title(\"Исходные данные\")\n","plt.show()"],"metadata":{"id":"xx8B-0FCEgPN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Реализация DBSCAN вручную"],"metadata":{"id":"PygNx4qkEwyo"}},{"cell_type":"code","source":["def euclidean_distance(x1, x2):\n","    \"\"\"\n","    Вычисляет евклидово расстояние между двумя точками.\n","\n","    Args:\n","        x1 (ndarray): Координаты первой точки.\n","        x2 (ndarray): Координаты второй точки.\n","\n","    Returns:\n","        float: Евклидово расстояние между точками.\n","    \"\"\"\n","    return np.sqrt(np.sum((x1 - x2) ** 2))\n","\n","assert np.isclose(euclidean_distance(np.array([1,2]), np.array([3,4])), 8**0.5)"],"metadata":{"id":"jwlufJ87EyNb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def region_query(X, x_center, epsilon):\n","    \"\"\"\n","    Находит соседей точки x_center в наборе данных X.\n","\n","    Args:\n","        X (ndarray): Набор данных.\n","        x_center (ndarray): Точка, для которой ищутся соседи.\n","        epsilon (float): Радиус окрестности.\n","\n","    Returns:\n","        list: Список индексов соседей точки x_center в X.\n","    \"\"\"\n","    neighbors = []\n","    for i, point in enumerate(X):\n","        if euclidean_distance(x_center, point) <= epsilon:\n","            neighbors.append(i)\n","    return neighbors\n","\n","assert np.isclose(region_query(X[:3], np.array([1,1]), 0.5), np.array([2])).all()\n","assert np.isclose(region_query(X[:3], np.array([1,1]), 0.7), np.array([1,2])).all()"],"metadata":{"id":"PSQgq1TzE1U1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def is_core_object(X, x_index, epsilon, m):\n","    \"\"\"\n","    Определяет, является ли объект корневым.\n","\n","    Args:\n","        X (ndarray): Набор данных.\n","        x_index (int): Индекс объекта в X.\n","        epsilon (float): Радиус окрестности.\n","        m (int): Минимальное количество соседей.\n","\n","    Returns:\n","        bool: True, если объект является корневым, False иначе.\n","    \"\"\"\n","    x_center = X[x_index]\n","    neighbors = region_query(X, x_center, epsilon)\n","    return len(neighbors) >= m\n","\n","assert is_core_object(X[:10], 7, 0.5, 3) == True\n","assert is_core_object(X[:10], 6, 0.5, 3) == False"],"metadata":{"id":"9RLiosDqE4ua"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dbscan(X, epsilon, m):\n","    \"\"\"\n","    Реализует алгоритм DBSCAN.\n","\n","    Args:\n","        X (ndarray): Набор данных.\n","        epsilon (float): Радиус окрестности (eps).\n","        m (int): Минимальное количество соседей (min_pts).\n","\n","    Returns:\n","        ndarray: Массив меток кластеров для каждой точки (-1 - выброс).\n","    \"\"\"\n","    n = len(X)\n","    labels = np.zeros(n, dtype=int) - 1  # Изначально все точки помечены как выбросы (-1)\n","    cluster_id = 0\n","\n","    for i in tqdm(range(n)):\n","        if labels[i] != -1:  # Уже обработан\n","            continue\n","\n","        if is_core_object(X, i, epsilon, m):\n","            cluster_id += 1\n","            labels[i] = cluster_id\n","            neighbors = region_query(X, X[i], epsilon)\n","\n","            # Расширяем кластер\n","            j = 0\n","            while j < len(neighbors):\n","                neighbor_index = neighbors[j]\n","                if labels[neighbor_index] == -1:  # Еще не посещен\n","                    labels[neighbor_index] = cluster_id\n","                elif labels[neighbor_index] == 0: #Граничный объект\n","                    labels[neighbor_index] = cluster_id\n","                neighbors_of_neighbor = region_query(X, X[neighbor_index], epsilon)\n","                if len(neighbors_of_neighbor) >= m: #сосед является корневым объектом\n","                    for neighbor in neighbors_of_neighbor:\n","                        if neighbor not in neighbors:\n","                            neighbors.append(neighbor)\n","                j += 1\n","\n","    return labels"],"metadata":{"id":"aUVMaLQ6Eplz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Параметры DBSCAN\n","epsilon = 0.2\n","m = 5\n","\n","# Запускаем DBSCAN\n","labels = dbscan(X, epsilon, m)"],"metadata":{"id":"ujMOL1-KGizW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Сравнение с библиотечной реализацией (sklearn)"],"metadata":{"id":"ps8gA-L_F5lF"}},{"cell_type":"code","source":["# Инициализация DBSCAN из sklearn\n","dbscan_sklearn = DBSCAN(eps=epsilon, min_samples=m)\n","\n","# Обучение модели\n","clusters_sklearn = dbscan_sklearn.fit_predict(X)"],"metadata":{"id":"MZ8eLdNcEgUm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Сравним результаты визуально (а также можно оценить метрики, если известна истинная кластеризация)\n","\n","# Создаем фигуру и две подграфика в одной строке\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n","\n","# Подграфик для вашей реализации DBSCAN\n","ax1.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n","ax1.set_title('DBSCAN (Numpy)')\n","\n","# Подграфик для DBSCAN из sklearn\n","ax2.scatter(X[:, 0], X[:, 1], c=clusters_sklearn, cmap='viridis')\n","ax2.set_title('DBSCAN (sklearn)')\n","\n","# Отображаем общую фигуру\n","plt.show()"],"metadata":{"id":"ieSTq59zEgXL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Важные замечания:**\n","\n","*   При фиксированных параметрах алгоритма ($m$ и $\\varepsilon$), корневые элементы, если они есть, распределяются по кластерам однозначно. То же самое касается и выбросов.  Однако, граничные объекты могут менять кластерную принадлежность в зависимости от порядка выбора корневых элементов.\n","*   Перед кластеризацией имеет смысл стандартизировать или нормировать признаки кластеризуемых объектов, так как понятия корневого объекта и соседей зависят от расстояния.\n","*   Подбор оптимальных параметров алгоритма DBSCAN является сложной задачей."],"metadata":{"id":"785LArIyEe69"}}]}