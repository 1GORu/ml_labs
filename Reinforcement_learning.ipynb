{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["q9QLe_T6GZUd"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"q9QLe_T6GZUd"},"source":["# Reinforcement Learning (RL)"]},{"cell_type":"markdown","metadata":{"id":"EYlIf2yHv8hz"},"source":["**Выполнять задание следует с текущими значениями гиперпараметров. Для проверки ниже будут приведены ответы, которые должны получиться в результате выполнения задания.**"]},{"cell_type":"markdown","metadata":{"id":"ZDQzNIZXAoFE"},"source":["Зададим гиперпараметры модели"]},{"cell_type":"code","source":["import gym\n","import numpy as np\n","import time\n","from IPython.display import clear_output\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt"],"metadata":{"id":"0m0A0fltfNzZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NOMw2ZbOAmOZ"},"source":["epsilon = 0.1      # Параметр эпсилон при использовании эпсилон жадной стратегии\n","gamma = 0.8        # Коэффциент дисконтирования гамма\n","random_seed = 100  # Random seed\n","time_delay = 1     # Задержка времени при отрисовке процесса игры после обучения (секунды)\n","lr_rate = 0.9      # Коэффициент скорости обучения альфа"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQu5IYHX8jId"},"source":["Импортируем библиотеки, создаем свою среду размера 6х6. S обозначает точку старта. F -- лед безопасен, H -- проталина, G -- цель. Параметр `is_slippery=False` отвечает за условное отсутствие скольжения. То есть если агент выбрал действие пойти направо, то он переместится в соответствующее состояние. В общем случае из-за \"скольжения\" можно оказаться в другом состоянии. Мы также скопировали из библиотки GYM и слегка модифицировали функцию ```generate_random_map ```, для того, чтобы генерировать произвольные карты на основе ```random_seed ```."]},{"cell_type":"code","source":["# Установим нужную версию библиотеки gym\n","!git clone https://github.com/dvolchek/gym_0_18_0.git -q\n","%cd /content/gym_0_18_0\n","!pip install -e. -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NjKH2tVSK2m0","executionInfo":{"status":"ok","timestamp":1761398006758,"user_tz":-180,"elapsed":15432,"user":{"displayName":"Iguru Obanai","userId":"09453581476284974492"}},"outputId":"f82963cf-580f-4134-dacf-6f4877c852fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'gym_0_18_0' already exists and is not an empty directory.\n","/content/gym_0_18_0\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","metadata":{"id":"awL7CCCwD6C3","outputId":"e222ad41-8ee7-4f56-c5aa-37df2864a460","executionInfo":{"status":"ok","timestamp":1761398006766,"user_tz":-180,"elapsed":5,"user":{"displayName":"Iguru Obanai","userId":"09453581476284974492"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["def generate_random_map(size, p, sd):\n","    \"\"\"Generates a random valid map (one that has a path from start to goal)\n","    :param size: size of each side of the grid\n","    :param p: probability that a tile is frozen\n","    \"\"\"\n","    valid = False\n","    np.random.seed(sd)\n","\n","    # DFS to check that it's a valid path.\n","    def is_valid(res):\n","        frontier, discovered = [], set()\n","        frontier.append((0,0))\n","        while frontier:\n","            r, c = frontier.pop()\n","            if not (r,c) in discovered:\n","                discovered.add((r,c))\n","                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n","                for x, y in directions:\n","                    r_new = r + x\n","                    c_new = c + y\n","                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n","                        continue\n","                    if res[r_new][c_new] == 'G':\n","                        return True\n","                    if (res[r_new][c_new] not in '#H'):\n","                        frontier.append((r_new, c_new))\n","        return False\n","\n","    while not valid:\n","        p = min(1, p)\n","        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n","        res[0][0] = 'S'\n","        res[-1][-1] = 'G'\n","        valid = is_valid(res)\n","    return [\"\".join(x) for x in res]\n","\n","#Генерация карты\n","random_map = generate_random_map(size=6, p=0.8, sd = random_seed) #Создаем свою карту\n","env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) #Инициализируем среду\n","print(\"Ваша карта\")\n","env.render() #Выводим карту на экран"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ваша карта\n","\n","\u001b[41mS\u001b[0mFFHFF\n","FHFFHF\n","FFFHHF\n","HFFHHF\n","FFFFFF\n","FFFFFG\n"]}]},{"cell_type":"markdown","metadata":{"id":"MDCexoEU9a_c"},"source":["Функции выбора действия и обновления таблицы ценности действий. Строчка *** используется для того, чтобы проверять ответы в openedx. Вне рамках академической задачи лучше использовать оригинальный метод класса `environment`, то есть:\n","\n","`action = env.action_space.sample()`"]},{"cell_type":"markdown","metadata":{"id":"D5TbDqn6G_Pt"},"source":["# Задача 1\n","Дополните функцию ```learn()```, чтобы в результате ее вызова обновлялось значение ценности текущего действия согласно алгоритму Q-обучения\n"]},{"cell_type":"code","metadata":{"id":"CdQBpxaTOK7u"},"source":["def choose_action(state):\n","    action=0\n","    if np.random.uniform(0, 1) < epsilon:\n","        action = np.random.randint(0,env.action_space.n) #***\n","    else:\n","        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n","    return action\n","\n","def learn(state, state2, reward, action, done):\n","    \"\"\"\n","    Обновляет Q-значение по правилу Q-обучения.\n","\n","    Параметры:\n","    - state: текущее состояние (int)\n","    - state2: следующее состояние (int)\n","    - reward: полученная награда (float)\n","    - action: выбранное действие (int)\n","    - done: завершён ли эпизод (bool)\n","    \"\"\"\n","    if done:\n","        # Если эпизод окончен, будущие вознаграждения отсутствуют\n","        td_target = reward\n","    else:\n","        # Иначе: r + γ * max_a' Q(s', a')\n","        td_target = reward + gamma * np.max(Q[state2, :])\n","\n","    # Обновление по формуле: Q(s,a) = Q(s,a) + α * (target - Q(s,a))\n","    Q[state, action] = Q[state, action] + lr_rate * (td_target - Q[state, action])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7COGeyA_Ist3"},"source":["# Задача 2\n","Дополните следующий код так, чтобы в результате обучения модели можно было узнать количество побед и номер игры (`game`), на котором агент впервые одержал пятую победу подряд."]},{"cell_type":"markdown","metadata":{"id":"0adDl7NvJoQP"},"source":["Поясним, что возвращает функция ```env.step(action)```\n","\n","```state2``` -- следующее состояние\n","\n","```reward``` -- награда\n","\n","```done``` -- флаг окончания игры. True в случае победы или падения в проталину. False в остальных случаях.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"aq92-dWiOchF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cdd856ee-6afc-460d-f026-a99e37a1dbaf","executionInfo":{"status":"ok","timestamp":1761398019778,"user_tz":-180,"elapsed":12996,"user":{"displayName":"Iguru Obanai","userId":"09453581476284974492"}}},"source":["# Инициализация\n","np.random.seed(random_seed)\n","total_games = 10000\n","max_steps = 100\n","Q = np.zeros((env.observation_space.n, env.action_space.n))\n","\n","# Счётчики\n","win_streak = 0\n","win_count = 0\n","first_five_in_a_row = -1  # будет установлен только один раз\n","\n","for game in tqdm(range(total_games)):\n","    state = env.reset()\n","    t = 0\n","    while t < max_steps:\n","        t += 1\n","        action = choose_action(state)\n","        state2, reward, done, info = env.step(action)\n","\n","        if t == max_steps:\n","            done = True\n","\n","        learn(state, state2, reward, action, done)\n","        state = state2\n","\n","        if done:\n","            break\n","\n","    # После завершения игры анализируем результат\n","    if reward == 1:  # Победа\n","        win_count += 1\n","        win_streak += 1\n","        if win_streak == 5 and first_five_in_a_row == -1:\n","            first_five_in_a_row = game + 1  # game начинается с 0, но мы хотим номер игры (1-based)\n","    else:  # Проигрыш\n","        win_streak = 0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10000/10000 [00:12<00:00, 769.41it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"JFuxsqdRLOS9"},"source":["Вывод ответов при заданных параметрах"]},{"cell_type":"code","metadata":{"id":"xZbJtFnhLa7w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761398019825,"user_tz":-180,"elapsed":33,"user":{"displayName":"Iguru Obanai","userId":"09453581476284974492"}},"outputId":"e4265751-c938-44bc-d61c-be0787fe05da"},"source":["print(\"Количество побед в серии из 10 000 игр: \", win_count)\n","print(\"Пять побед подряд впервые было одержано в игре \", first_five_in_a_row)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество побед в серии из 10 000 игр:  7914\n","Пять побед подряд впервые было одержано в игре  885\n"]}]},{"cell_type":"markdown","metadata":{"id":"TSXdSiG2WI71"},"source":["Должны получиться следующие результаты.\n","\n","\n","*  Количество побед в серии из 10 000 игр:  7914\n","*  Пять побед подряд впервые было одержано в игре  885\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nazZaAbwQGBt"},"source":["Произведем одну игру, чтобы проследить за действиями агента. При этом будем считать модель полностью обученной, то есть действия выбираются жадно, значения ценностей действий в таблице не обновляются."]},{"cell_type":"code","metadata":{"id":"5ysllZjEQXLa","outputId":"0464a79e-b1fc-4c2d-9bbd-49bdebda60e8","executionInfo":{"status":"ok","timestamp":1761398029900,"user_tz":-180,"elapsed":10072,"user":{"displayName":"Iguru Obanai","userId":"09453581476284974492"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Жадный выбор действий\n","def choose_action_one_game(state):\n","    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n","    return action\n","\n","states=[]#Массив для сохранения состояний агента в течение игры\n","t = 0\n","state = env.reset()\n","wn = 0\n","while(t<100):\n","  env.render()\n","  time.sleep(time_delay)\n","  clear_output(wait=True)\n","  action = choose_action_one_game(state)\n","  state2, reward, done, info = env.step(action)\n","  states.append(state)\n","  state = state2\n","  t += 1\n","  if done and reward == 1:\n","    wn=1\n","  if done:\n","    break\n","if wn == 1:\n","  print(\"!!!Победа!!!\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["!!!Победа!!!\n"]}]},{"cell_type":"markdown","metadata":{"id":"x696NulpReFI"},"source":["Отобразим маршрут"]},{"cell_type":"code","metadata":{"id":"UKMCMdpOTcXy","outputId":"8b961648-0cd3-4357-906c-5566509f23e1","executionInfo":{"status":"ok","timestamp":1761398236756,"user_tz":-180,"elapsed":145,"user":{"displayName":"Iguru Obanai","userId":"09453581476284974492"}},"colab":{"base_uri":"https://localhost:8080/","height":487}},"source":["def make_maze_pic(maze):\n","  maze_pic=[]\n","  for i in range(len(maze)):\n","    row = []\n","    for j in range(len(maze[i])):\n","      if maze[i][j] == 'S':\n","        row.append(0)\n","      if maze[i][j] == 'F':\n","        row.append(0)\n","      if maze[i][j] == 'H':\n","        row.append(1)\n","      if maze[i][j] == 'G':\n","        row.append(0)\n","    maze_pic.append(row)\n","  maze_pic = np.array(maze_pic)\n","  return maze_pic\n","\n","\n","#Make maze fit to plot\n","maze_pic = make_maze_pic(random_map)\n","nrows, ncols = maze_pic.shape\n","\n","#Arrays of picture elements\n","rw = np.remainder(states,nrows)\n","cl = np.floor_divide(states,nrows)\n","if wn == 1:\n","  rw = np.append(rw, [nrows-1])\n","  cl = np.append(cl,[ncols-1])\n","\n","#Picture plotting\n","fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n","ax1.clear()\n","ax1.set_xticks(np.arange(0.5, nrows, step=1))\n","ax1.set_xticklabels([])\n","ax1.set_yticks(np.arange(0.5, ncols, step=1))\n","ax1.set_yticklabels([])\n","ax1.grid(True)\n","ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n","ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n","ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n","ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n","ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n","ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n","ax1.imshow(maze_pic, cmap=\"binary\")\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"5m14YFyrI6M0"},"source":["# Задача 3"]},{"cell_type":"markdown","metadata":{"id":"lb3BvDuBxTO0"},"source":["Используйте вместо алгоритма Q-обучения алгоритм SARSA. Обратите внимание на то, что требуется изменить количество игр. То есть `total_games = 40000`. Запускать блоки следует последвательно с самого начала (из-за `random_seed`). Отдельно обращаем ваше внимание на то, что при изменении алгоритма с Q-обучения на SARSA модификации подлежит как процесс обучения, так и функция `learn()`. Кроме того, у функции `learn()` должен появиться дополнительный аргумент (следующее действие). Ниже приведен фрагмент кода с пояснениями, как именно нужно модифицировать алгоритм."]},{"cell_type":"code","source":["def learn(state, state2, reward, action, action2, done):\n","    # Обновление SARSA\n","    if done:\n","        td_target = reward\n","    else:\n","        td_target = reward + gamma * Q[state2, action2]\n","\n","    Q[state, action] = Q[state, action] + lr_rate * (td_target - Q[state, action])"],"metadata":{"id":"9NRhcKCfAWFM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Инициализация\n","np.random.seed(random_seed)\n","total_games = 40000\n","max_steps = 100\n","Q = np.zeros((env.observation_space.n, env.action_space.n))\n","\n","# Счётчики\n","win_streak = 0\n","win_count = 0\n","first_five_in_a_row = -1\n","\n","# Основной цикл\n","for game in tqdm(range(total_games)):\n","    state = env.reset()\n","    action = choose_action(state)  # Выбор первого действия\n","    t = 0\n","\n","    while t < max_steps:\n","        t += 1\n","\n","        # Делаем шаг\n","        state2, reward, done, info = env.step(action)\n","\n","        # Выбираем следующее действие заранее (для SARSA)\n","        action2 = choose_action(state2)\n","\n","        # Дополнительное условие: ограничение по шагам\n","        if t == max_steps:\n","            done = True\n","\n","        # Обучение SARSA: используем action2\n","        learn(state, state2, reward, action, action2, done)\n","\n","        # Переход к следующему шагу\n","        state = state2\n","        action = action2  # действие для следующей итерации\n","\n","        if done:\n","            break\n","\n","    # Анализ результата игры\n","    if reward == 1:\n","        win_count += 1\n","        win_streak += 1\n","        if win_streak == 5 and first_five_in_a_row == -1:\n","            first_five_in_a_row = game + 1  # игра с 1 (не с 0)\n","    else:\n","        win_streak = 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ib-TO0tvAe00","executionInfo":{"status":"ok","timestamp":1761398065000,"user_tz":-180,"elapsed":34869,"user":{"displayName":"Iguru Obanai","userId":"09453581476284974492"}},"outputId":"a84baace-e933-4ff9-a6df-03162fca801b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 40000/40000 [00:34<00:00, 1144.81it/s]\n"]}]},{"cell_type":"code","source":["print(\"Количество побед в серии из 40 000 игр: \", win_count)\n","print(\"Пять побед подряд впервые было одержано в игре \", first_five_in_a_row)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bLlBi8POBDNz","executionInfo":{"status":"ok","timestamp":1761398065018,"user_tz":-180,"elapsed":21,"user":{"displayName":"Iguru Obanai","userId":"09453581476284974492"}},"outputId":"c7bf1ef9-8307-4cab-9e35-30cd867914c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество побед в серии из 40 000 игр:  32328\n","Пять побед подряд впервые было одержано в игре  894\n"]}]},{"cell_type":"markdown","metadata":{"id":"RB_PX2vYIY0-"},"source":["В результате обучения должны получиться следующие ответы:\n","*   Количество побед в серии из 40 000 игр:  32328\n","*   Пять побед подряд впервые было одержано в игре  894"]}]}